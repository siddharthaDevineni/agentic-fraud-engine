server:
  port: 8080

spring:
  application:
    name: agentic-fraud-engine

  # Spring AI Configuration
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        options:
          model: llama3.2
          temperature: 0.1
          num-predict: 4096     # Max output tokens
          num-ctx: 8192         # Context window
          num-thread: 8         # CPU threads
          num-gpu: 1            # Use GPU if available
          repeat-penalty: 1.1   # Reduce repetition
          top-k: 40
          top-p: 0.9

  # Kafka Configuration
  kafka:
    bootstrap-servers: localhost:9092
    consumer:
      group-id: fraud-engine
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring.json.trusted.packages: com.agenticfraud.engine.models
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer

# Actuator for monitoring
management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus,metrics
  endpoint:
    health:
      show-details: always

# Logging
logging:
  level:
    com.agenticfraud: DEBUG
    org.springframework.ai: DEBUG
    org.apache.kafka: INFO